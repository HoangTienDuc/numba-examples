{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba 0.46.0 Release Demo for Library Developers\n",
    "==========================================\n",
    "\n",
    "This Notebook contains demonstrations of new features in the 0.46 release of Numba that are intended for use by library developers/compiler engineers.\n",
    "\n",
    "\n",
    "<h3 align=\"center\">üö®üêâüö® These are advanced features, dragons be 'ere! üö®üêâüö®</h3>\n",
    " \n",
    "Features demonstrated in this notebook include:\n",
    " * [Inlining at the Numba IR level](#Inlining)\n",
    " * [Customising the compiler](#Customising-the-compiler)\n",
    " * [Implementing a new compiler pipeline](#Implementing-a-new-pipeline)\n",
    " * [Writing compiler passes](#Implementing-a-new-compiler-pass)\n",
    " \n",
    "Other new features present but not demonstrated here include:\n",
    "  * Support of literal typing. [Documentation here](http://numba.pydata.org/numba-doc/latest/developer/literal.html).\n",
    "  * An API for using the Numba Runtime from external `C` modules and associated helper functions. [Documentation here](http://numba.pydata.org/numba-doc/latest/developer/numba-runtime.html#using-the-nrt-from-c-code).\n",
    "  * Module at a time application of the `jit` decorator. [Documentation here](http://numba.pydata.org/numba-doc/latest/user/jit-module.html).\n",
    "  \n",
    "  \n",
    "First, import the necessary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, njit, config, __version__, errors\n",
    "from numba.extending import overload\n",
    "import numpy as np\n",
    "assert tuple(int(x) for x in __version__.split('.')[:2]) >= (0, 46)\n",
    "config.SHOW_HELP = False # switch off help messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inlining\n",
    "----------\n",
    "\n",
    "Numba gains a lot from LLVM itself being able to inline functions, and Numba's internals are geared towards making it easy. However, numerous use cases have arisen where it would be useful to be able to inline a function at the Numba IR level. Numba 0.46 adds support for doing this via the keyword argument `inline` that can be supplied to the `numba.jit` family of decorators and also `numba.extending.overload`, documentation is [here](http://numba.pydata.org/numba-doc/latest/developer/inlining.html).\n",
    "\n",
    "A motivating use case, the following function obviously can be compiled without issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.typed import List\n",
    "\n",
    "@njit\n",
    "def foo():\n",
    "    l = List()\n",
    "    for i in range(10):\n",
    "        l.append(i * 123.45)\n",
    "    return l\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This minor variation on the above cannot be compiled, the type of the `List()` in `bar` cannot be inferred as type inference cannot \"see\" across the function call into `baz` where it becomes apparent the type must be a `ListType[float64]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def baz(l):\n",
    "    for i in range(10):\n",
    "        l.append(i * 123.45)\n",
    "\n",
    "@njit\n",
    "def bar():\n",
    "    l = List()\n",
    "    baz(l)\n",
    "    return l\n",
    "\n",
    "try:\n",
    "    bar()\n",
    "except errors.TypingError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something similar to the above use case was the exact reason the ability to perform inlining was explored. The following demonstrates how to resolve the above situation, supplying the kwarg `inline='always'` to the called function will force it's body to be inlined at the call site in the caller, hence there's now no type inference issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(inline='always')\n",
    "def baz(l):\n",
    "    for i in range(10):\n",
    "        l.append(i * 123.45)\n",
    "\n",
    "@njit\n",
    "def bar():\n",
    "    l = List()\n",
    "    baz(l)\n",
    "    return l\n",
    "\n",
    "bar() # works fine\n",
    "\n",
    "# baz got inlined, bar was effectively seen as:\n",
    "# def bar():\n",
    "#     l = List()\n",
    "#     for i in range(10):\n",
    "#         l.append(i * 123.45)\n",
    "#     return l\n",
    "#\n",
    "# which is the same as foo above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlining options\n",
    "\n",
    "To make the inlining capability as flexible as possible three options were added for the kwarg:\n",
    " * `'never'` - never inline (default)\n",
    " * `'always'` - always inline\n",
    " * a callable - returns True to inline, False to not inline\n",
    " \n",
    " \n",
    "An example using all of the above follows (it also uses the new environment variable/config option `DEBUG_PRINT_AFTER` to show the IR, docs are [here](http://numba.pydata.org/numba-doc/latest/reference/envvars.html?#envvar-NUMBA_DEBUG_PRINT_AFTER)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, ir\n",
    "import numba\n",
    "\n",
    "# enable printing of the IR post legalization, i.e. just before it is lowered\n",
    "numba.config.DEBUG_PRINT_AFTER=\"ir_legalization\"\n",
    "\n",
    "\n",
    "@njit(inline='never')\n",
    "def never_inline():\n",
    "    return 100\n",
    "\n",
    "\n",
    "@njit(inline='always')\n",
    "def always_inline():\n",
    "    return 200\n",
    "\n",
    "\n",
    "def sentinel_cost_model(expr, caller_info, callee_info):\n",
    "    # this cost model will return True (i.e. do inlining) if either:\n",
    "    # a) the callee IR contains an `ir.Const(37)`\n",
    "    # b) the caller IR contains an `ir.Const(13)` logically prior to the call\n",
    "    #    site\n",
    "\n",
    "    # check the callee\n",
    "    for blk in callee_info.blocks.values():\n",
    "        for stmt in blk.body:\n",
    "            if isinstance(stmt, ir.Assign):\n",
    "                if isinstance(stmt.value, ir.Const):\n",
    "                    if stmt.value.value == 37:\n",
    "                        return True\n",
    "\n",
    "    # check the caller\n",
    "    before_expr = True\n",
    "    for blk in caller_info.blocks.values():\n",
    "        for stmt in blk.body:\n",
    "            if isinstance(stmt, ir.Assign):\n",
    "                if isinstance(stmt.value, ir.Expr):\n",
    "                    if stmt.value == expr:\n",
    "                        before_expr = False\n",
    "                if isinstance(stmt.value, ir.Const):\n",
    "                    if stmt.value.value == 13:\n",
    "                        return True & before_expr\n",
    "    return False\n",
    "\n",
    "\n",
    "@njit(inline=sentinel_cost_model)\n",
    "def maybe_inline1():\n",
    "    # Will not inline based on the callee IR with the declared cost model\n",
    "    # The following is ir.Const(300).\n",
    "    return 300\n",
    "\n",
    "\n",
    "@njit(inline=sentinel_cost_model)\n",
    "def maybe_inline2():\n",
    "    # Will inline based on the callee IR with the declared cost model\n",
    "    # The following is ir.Const(37).\n",
    "    return 37\n",
    "\n",
    "\n",
    "@njit\n",
    "def foo():\n",
    "    a = never_inline()  # will never inline\n",
    "    b = always_inline()  # will always inline\n",
    "\n",
    "    # will not inline as the function does not contain a magic constant known to\n",
    "    # the cost model, and the IR up to the call site does not contain a magic\n",
    "    # constant either\n",
    "    d = maybe_inline1()\n",
    "\n",
    "    # declare this magic constant to trigger inlining of maybe_inline1 in a\n",
    "    # subsequent call\n",
    "    magic_const = 13\n",
    "\n",
    "    # will inline due to above constant declaration\n",
    "    e = maybe_inline1()\n",
    "\n",
    "    # will inline as the maybe_inline2 function contains a magic constant known\n",
    "    # to the cost model\n",
    "    c = maybe_inline2()\n",
    "\n",
    "    return a + b + c + d + e + magic_const\n",
    "\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above IR, as dead code elimination is not performed by default, there are superfluous statements present.\n",
    "\n",
    "Further, the same `inline` kwarg is implemented for the `numba.extending.overload` decorator, documentation and examples are [here](http://numba.pydata.org/numba-doc/latest/developer/inlining.html#example-using-numba-extending-overload)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba.config.DEBUG_PRINT_AFTER=\"\" # disable debug print again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customising the compiler\n",
    "=====================\n",
    "In Numba 0.46 the main compiler pipeline was significantly reworked to make it more easily extendable and to permit users to essentially build their own custom compiler frontends. This change is based on a design similar to that found in LLVM. Full documentation is [here](http://numba.pydata.org/numba-doc/latest/developer/custom_pipeline.html).\n",
    "\n",
    "\n",
    "Changing the default compiler\n",
    "--------------------------------------------\n",
    "For a large number of releases the Numba `@jit` family of decorators have permitted the definition of a custom compiler pipeline via the kwarg ``pipeline_class``, this has not changed, however the type of the class passed as the value has. Numba 0.46 now requires an instance of a `numba.compiler.CompilerBase` class to be passed as the value, this is a much more flexible class than the before mentioned pipeline.\n",
    "\n",
    "The default compiler used by Numba is the `numba.compiler.Compiler` class and it itself makes use of pre-canned pipelines defined in `numba.compiler.DefaultPassBuilder` by the methods:\n",
    "\n",
    " * `.define_nopython_pipeline()` for the nopython mode pipeline\n",
    " * `.define_objectmode_pipeline()` for the object-mode pipeline\n",
    " * `.define_interpreted_pipeline()` for the interpreted pipeline\n",
    "\n",
    "\n",
    "Creating a new custom compiler requires extending from the `numba.compiler.CompilerBase` class and overriding the `.define_pipelines()` method. e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.compiler import CompilerBase, DefaultPassBuilder\n",
    "class CustomCompiler(CompilerBase): # custom compiler extends from CompilerBase\n",
    "\n",
    "    def define_pipelines(self):\n",
    "        # define a new set of pipelines (just one in this case) and for demonstration purposes\n",
    "        # reuse an existing pipeline from the DefaultPassBuilder, namely the \"nopython\" pipeline\n",
    "        pm = DefaultPassBuilder.define_nopython_pipeline(self.state)\n",
    "        # return as an iterable, any number of pipelines may be defined!\n",
    "        return [pm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the custom compiler is just a question of supplying it via the aforementioned `pipeline_class` kwarg, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(pipeline_class=CustomCompiler)\n",
    "def foo(x):\n",
    "    return x + 1\n",
    "\n",
    "foo(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example won't work with the `CustomCompiler` because there's only the `nopython` mode pipeline available in the `CustomCompiler` and this function contains a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(pipeline_class=CustomCompiler)\n",
    "def foo(x):\n",
    "    return x + 1, object()\n",
    "\n",
    "from numba import errors\n",
    "try:\n",
    "    foo(10)\n",
    "except errors.TypingError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a new pipeline\n",
    "------------------------------------------\n",
    "Numba has a large number of pre-defined passes for use, they are categorised as being:\n",
    "\n",
    " * `untyped`, i.e. do not require type information, these are found in `numba.untyped_passes`\n",
    " * `typed`, i.e. require type information, these are found in `numba.typed_passes`\n",
    " * `object mode`, i.e. require object mode, these are found in `numba.object_mode_passes`\n",
    " \n",
    " \n",
    " For reference, these are the ones in the code base for 0.46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in numba.compiler_machinery._pass_registry._registry.keys():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a new pipeline that:\n",
    " * analyses the bytecode \n",
    " * rewrites semantic constants\n",
    " * does dead branch pruning\n",
    " * runs type inference\n",
    " * does dead code elimination\n",
    " * runs legalisation checks on the IR\n",
    " * lowers the IR to machine code\n",
    " \n",
    "and use it in a new custom compiler. The pipeline management code is found in `numba.compiler_machinery`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.compiler_machinery import PassManager\n",
    "\n",
    "from numba.untyped_passes import (TranslateByteCode, FixupArgs, IRProcessing, DeadBranchPrune,\n",
    "                                  RewriteSemanticConstants)\n",
    "\n",
    "from numba.typed_passes import (NopythonTypeInference, DeadCodeElimination, IRLegalization,\n",
    "                                NoPythonBackend)\n",
    "\n",
    "\n",
    "def gen_pipeline():\n",
    "    \"\"\" pipeline generation function, it need not be a function, pipelines are often\n",
    "    defined directly in `ClassExtendingCompilerBase.define_pipelines` but it'll be used\n",
    "    in a later example for another purpose.\n",
    "    \"\"\"\n",
    "    # create a new PassManager to handle the passes for the pipeline\n",
    "    pm = PassManager(\"custom_pipeline\")\n",
    "    \n",
    "    # untyped\n",
    "    pm.add_pass(TranslateByteCode, \"analyzing bytecode\")\n",
    "    pm.add_pass(IRProcessing, \"processing IR\")\n",
    "    pm.add_pass(RewriteSemanticConstants, \"rewrite semantic constants\")\n",
    "    pm.add_pass(DeadBranchPrune, \"dead branch pruning\")\n",
    "    \n",
    "    # typed\n",
    "    pm.add_pass(NopythonTypeInference, \"nopython frontend\")\n",
    "    pm.add_pass(DeadCodeElimination, \"DCE\")\n",
    "\n",
    "    # legalise\n",
    "    pm.add_pass(IRLegalization, \"ensure IR is legal prior to lowering\")\n",
    "\n",
    "    # lower\n",
    "    pm.add_pass(NoPythonBackend, \"nopython mode backend\")\n",
    "\n",
    "    # finalise the contents\n",
    "    pm.finalize()\n",
    "    return pm\n",
    "\n",
    "\n",
    "class NewPipelineCompiler(CompilerBase): \n",
    "\n",
    "    def define_pipelines(self):\n",
    "        return [gen_pipeline()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `NewPipelineCompiler` in a deliberately contrived example to demonstrate the effect of certain passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba.config.DEBUG_PRINT_AFTER=\"ir_processing,rewrite_semantic_constants,dead_branch_prune,dead_code_elimination\"\n",
    "\n",
    "\n",
    "@jit(pipeline_class=NewPipelineCompiler)\n",
    "def foo(arr):\n",
    "    if arr.ndim == 1:\n",
    "        return 100\n",
    "    else:\n",
    "        return 200\n",
    "\n",
    "x = np.arange(10) # 1d array input, x.ndim = 1\n",
    "foo(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, the following can be seen:\n",
    " * The `ir_processing` pass produces the inital IR.\n",
    " * The `rewrite_semantic_constants` pass replaces the expression:\n",
    "   - `$0.2 = getattr(value=arr, attr=ndim)` with `$0.2 = const(int, 1)`\n",
    " * The `dead_branch_prune` pass spotted that the block with `label 14` is dead and removed it because:\n",
    "    ```\n",
    "    $0.2 = const(int, 1)                     ['$0.2']\n",
    "    del arr                                  []\n",
    "    $const0.3 = const(int, 1)                ['$const0.3']\n",
    "    $0.4 = $0.2 == $const0.3 \n",
    "    ```\n",
    "    evaluates to `$0.4` always being `True` and as a result, it's use as the predicate in `branch $0.4, 10, 14` means the `10` branch will always be taken, `14` is dead.\n",
    " * The `dead_code_elimination` pass removed all the statements which were dead (had no effect).\n",
    " \n",
    "In the final output there are now two blocks, labels `0` and `10`. Block `0` has only one statement, an unconditional jump to `10`. In the next section a new pass is going to be written to simplify the control flow graph in such situations, as it's clear that the blocks can be fused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a new compiler pass\n",
    "---------------------------------------------------\n",
    "Implementing a new compiler pass involves writing a class that inherits from `numba.compiler_machinery.CompilerPass`. It must be registered with the pass registry before use and through the process of registration declare some information about what it will do in certain scenarios. Documentation for this feature is [here](http://numba.pydata.org/numba-doc/latest/developer/custom_pipeline.html#implementing-a-compiler-pass).\n",
    "\n",
    "Continuing with the above example, Numba has a function `numba.ir_utils.simplify_CFG` which does the control flow graph simplification alluded to in the final paragraph above. In the following this function is wrapped in a compiler pass and then used in a new pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.ir_utils import simplify_CFG\n",
    "from numba.compiler_machinery import register_pass, FunctionPass\n",
    "\n",
    "# Register this pass with the compiler framework, declare that it can mutate the control\n",
    "# flow graph and that it is not an analysis_only pass (it potentially mutates the IR).\n",
    "@register_pass(mutates_CFG=True, analysis_only=False)\n",
    "\n",
    "# Inherit from FunctionPass, the base class for passes operating on functions\n",
    "class SimplifyCFG(FunctionPass):\n",
    "    _name = \"simplify_cfg\" # the common name for the pass\n",
    "\n",
    "    def __init__(self):\n",
    "        FunctionPass.__init__(self)\n",
    "        \n",
    "    # implement the method to do the work, \"state\" is the internal compiler\n",
    "    # state from the CompilerBase instance.\n",
    "    def run_pass(self, state):\n",
    "        # get the IR blocks\n",
    "        blks = state.func_ir.blocks\n",
    "        # run the simplification\n",
    "        new_blks = simplify_CFG(blks)\n",
    "        # update the reference to the block state\n",
    "        state.func_ir.blocks = new_blks\n",
    "        \n",
    "        # return whether the IR was mutated (here, CFG change implies IR change)\n",
    "        mutated = blks != new_blks\n",
    "        return mutated\n",
    "\n",
    "\n",
    "# define a new compiler\n",
    "class NewPipelineWSimplifyCFGCompiler(CompilerBase):\n",
    "\n",
    "    def define_pipelines(self):\n",
    "        # generate the same pipeline as in the previous example\n",
    "        pm = gen_pipeline()\n",
    "        \n",
    "        # add the new pass after DeadCodeElimination\n",
    "        pm.add_pass_after(SimplifyCFG, DeadCodeElimination)\n",
    "        \n",
    "        # re-finalize the pipeline since the above mutated it\n",
    "        pm.finalize()\n",
    "        return [pm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now re-run the `foo` function again with the updated custom compiler including the new pass in its pipeline. Also, print the IR after dead code elimination (the end of output from the last example) and now after the new `SimplifyCFG` pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba.config.DEBUG_PRINT_AFTER=\"dead_code_elimination,simplify_cfg\"\n",
    "\n",
    "@jit(pipeline_class=NewPipelineWSimplifyCFGCompiler)\n",
    "def foo(arr):\n",
    "    if arr.ndim == 1:\n",
    "        return 100\n",
    "    else:\n",
    "        return 200\n",
    "\n",
    "x = np.arange(10) # 1d array input, x.ndim = 1\n",
    "foo(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen in the above that the CFG has been simplified after the new `simplify_cfg` pass has run, the IR is now a single block."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
